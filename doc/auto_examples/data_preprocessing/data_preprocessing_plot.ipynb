{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Preprocessing of the data\n\nFor each station, we follow these preprocessing steps:\n    - correction for constant shifts in some data (time, orientation).\n    - averaging of the in situ data in 1-hr bins centered on the time stamps of the Era5Land dataset.\n    - filtering unusued data (NaNs, 0 velocity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport os\nfrom scipy.stats import binned_statistic\nfrom datetime import datetime, timedelta\nimport matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\nimport sys\nsys.path.append('../../')\nfrom python_codes.general import cosd, sind\nimport python_codes.theme as theme\n#\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\ntheme.load_style()\n\n# paths\npath_savefig = '../../static/output_data/figures/'\npath_ouputdata = '../../static/output_data/data/'\npath_inputdata = '../../static/input_data'\n\nStations = ['Adamax_Station', 'Deep_Sea_Station', 'Huab_Station', 'South_Namib_Station']\n\nData = {}\n\nfor station in Stations:\n    Data[station] = {}\n    ############################################################################\n    # Loading data\n    ############################################################################\n    #\n    # ###### Era5Land wind data\n    path_Era5_land = os.path.join(path_inputdata, station, 'Era5Land_wind_data_' + station + '.npy')\n    Data_era = np.load(path_Era5_land, allow_pickle=True).item()\n    #\n    t_era = Data_era['time']\n    U_era = np.sqrt(Data_era['Uwind']**2 + Data_era['Vwind']**2).squeeze()\n    Orientation_era = (np.arctan2(Data_era['Vwind'], Data_era['Uwind'])*180/np.pi).squeeze() % 360\n    # ###### in situ wind data\n    path_insitu = os.path.join(path_inputdata, station, 'in_situ_wind_data_' + station + '.npy')\n    Data_insitu = np.load(path_insitu, allow_pickle=True).item()\n    #\n    t_station = Data_insitu['time']\n    U_station = Data_insitu['velocity']\n    # putting angles in trigo. ref.\n    Orientation_station = (270 - Data_insitu['direction']) % 360\n    #\n    ############################################################################\n    # Averaging in situ data over 1hr\n    ############################################################################\n    dt = timedelta(minutes=60)  # bin size for averaging\n    tmin, tmax = t_era[0].replace(minute=0), t_era[-1].replace(minute=50)\n    t_station_hourly = np.arange(tmin - dt/2, tmax + dt/2, dt).astype(datetime)  # centered on Era5Land time steps\n    # #### Using number of seconds from tmin for averaging function\n    diff_time_seconds = [i.total_seconds() for i in (t_station - tmin)]\n    bins_seconds = [i.total_seconds() for i in (t_station_hourly - tmin)]\n    #\n    # #### Averaging into bins\n    U_av, bin_edges, _ = binned_statistic(diff_time_seconds, [U_station*cosd(Orientation_station), U_station*sind(Orientation_station)],\n                                          bins=bins_seconds, statistic=np.nanmean)\n    #\n    Orientation_av = (np.arctan2(U_av[1, :], U_av[0, :])*180/np.pi) % 360  # orientation time series\n    U_av = np.linalg.norm(U_av, axis=0)  # velocity time series\n    bin_centered = bin_edges[1:] - (bin_edges[1] - bin_edges[0])/2\n    t_station_avg = tmin + np.array([timedelta(seconds=i) for i in bin_centered])\n    # Note: at this point, the in situ data are mapped on the ERA5 time steps, with a lot of NaNs where there was no in situ data.\n    #\n    ############################################################################\n    # Filtering unusued data (NaNs, 0 velocity)\n    ############################################################################\n    mask = (~ (np.isnan(U_av) | np.isnan(Orientation_av))) & (U_av > 0)\n    #\n    # #### Storing data into dictionnary\n    Data[station]['U_station'] = U_av[mask]\n    Data[station]['Orientation_station'] = Orientation_av[mask]\n    Data[station]['time'] = t_station_avg[mask]\n    #\n    Data[station]['U_era'] = U_era[mask]\n    Data[station]['Orientation_era'] = Orientation_era[mask]\n    # check that time periods agrees\n    ############################################################################\n    # If available, do the same for the meteorological data from Era5\n    ############################################################################\n    if station in ['South_Namib_Station', 'Deep_Sea_Station']:\n        # BLH\n        path_Era5_land = os.path.join(path_inputdata, station, 'Era5_BLH_' + station + '.npy')\n        Data_BLH = np.load(path_Era5_land, allow_pickle=True).item()\n        Data[station]['Boundary layer height'] = Data_BLH['Boundary layer height'][mask]\n        # Pressure level data\n        path_Era5_land = os.path.join(path_inputdata, station, 'Era5_level_' + station + '.npy')\n        Data_level = np.load(path_Era5_land, allow_pickle=True).item()\n        Data[station]['Pressure levels'] = Data_level['Pressure levels']\n        inds_mask = np.arange(t_era.size)[mask]\n        for key in Data_level.keys():\n            if key not in ['time', 'Pressure levels']:\n                Data[station][key] = Data_level[key][..., inds_mask]\n\n    # figure for comparison\n    if station == 'South_Namib_Station':\n        tmin, tmax = datetime(2017, 6, 1), datetime(2017, 6, 10)\n        fig = plt.figure(figsize=(theme.fig_width, 0.9*theme.fig_width))\n        ax1 = plt.subplot(2, 1, 1)\n        plt.plot(t_station, Orientation_station, label='Raw data')\n        plt.plot(t_station_avg, Orientation_av, label='Binned data')\n        plt.xlabel('Days in June 2017')\n        plt.ylabel('Orientation~[deg.]')\n        plt.xlim(tmin, tmax)\n        myFmt = mdates.DateFormatter('%d')\n        ax1.xaxis.set_major_formatter(myFmt)\n        plt.ylim(0, 360)\n        plt.yticks([0, 90, 180, 270, 360])\n        #\n        ax2 = plt.subplot(2, 1, 2)\n        plt.plot(t_station, U_station, label='Raw data')\n        plt.plot(t_station_avg, U_av, label='Binned data')\n        plt.xlabel('Days in June 2017')\n        plt.ylabel('Velocity~[m/s]')\n        plt.xlim(tmin, tmax)\n        plt.ylim(bottom=0)\n        myFmt = mdates.DateFormatter('%d')\n        ax2.xaxis.set_major_formatter(myFmt)\n        plt.legend()\n        plt.subplots_adjust(0.09, 0.08, 0.99, 0.99, hspace=0.25)\n        plt.savefig(os.path.join(path_savefig, 'temporal_binning.pdf'))\n        plt.show()\n\npath_save = os.path.join(path_ouputdata, 'Data_preprocessed.npy')\nnp.save(path_save, Data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}