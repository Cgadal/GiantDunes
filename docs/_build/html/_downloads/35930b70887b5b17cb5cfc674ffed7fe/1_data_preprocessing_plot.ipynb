{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Preprocessing of the wind data\n\nFor each station, we follow these preprocessing steps:\n\n    - put the wind direction in the trigonometric referential (counter clockwise, 0 in the WE-direction).\n    - averaging of the in situ data in 1-hr bins centered on the time stamps of the Era5Land dataset.\n    - filtering unusued data (NaNs, 0 velocity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport sys\nimport glob\nimport numpy as np\nfrom scipy.stats import binned_statistic\nfrom datetime import datetime, timedelta\nsys.path.append('../')\nfrom python_codes.general import cosd, sind\nimport python_codes.theme as theme\n#\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\ntheme.load_style()\n\nNames = {\n        'u10': '10 metre U wind component',\n        'v10': '10 metre V wind component',\n        'blh': 'Boundary layer height',\n        't': 'Temperature',\n        'q': 'Specific humidity',\n        'z': 'Geopotential',\n        'levels': 'Pressure levels'\n        }\n\n# paths\npath_outputdata = '../static/data/processed_data/'\npath_inputdata = '../static/data/raw_data'\n\nStations = ['Adamax_Station', 'Deep_Sea_Station', 'Huab_Station', 'South_Namib_Station']\n\nlist_file_ERA5Land = glob.glob(os.path.join(path_inputdata, 'ERA5Land/*.npy'))\nlist_file_ERA5 = glob.glob(os.path.join(path_inputdata, 'ERA5/*.npy'))\nlist_file_insitu = glob.glob(os.path.join(path_inputdata, 'measured_wind_data/*.npy'))\n\nData = {}\n\nfor station in Stations:\n    Data[station] = {}\n    ############################################################################\n    # Loading data\n    ############################################################################\n    #\n    # ###### Era5Land wind data\n    path_ERA5Land = [file for file in list_file_ERA5Land if station in file][0]\n    Data_ERA5Land = np.load(path_ERA5Land, allow_pickle=True).item()\n    #\n    t_era = np.array([i.replace(tzinfo=None) for i in Data_ERA5Land['time']])\n    U_era = np.sqrt(Data_ERA5Land['u10']**2 + Data_ERA5Land['v10']**2).squeeze()\n    Orientation_era = (np.arctan2(Data_ERA5Land['v10'], Data_ERA5Land['u10'])*180/np.pi).squeeze() % 360\n    # ###### in situ wind data\n    path_insitu = [file for file in list_file_insitu if station in file][0]\n    Data_insitu = np.load(path_insitu, allow_pickle=True).item()\n    #\n    t_insitu = Data_insitu['time']\n    U_insitu = Data_insitu['velocity']\n    # putting angles in trigo. ref.\n    Orientation_insitu = (270 - Data_insitu['direction']) % 360\n    #\n    ############################################################################\n    # Averaging in situ data over 1hr\n    ############################################################################\n    dt = timedelta(minutes=60)  # bin size for averaging\n    tmin, tmax = t_era[0].replace(minute=0), t_era[-1].replace(minute=50)\n    t_insitu_hourly = np.arange(tmin - dt/2, tmax + dt/2, dt).astype(datetime)  # centered on Era5Land time steps\n    # #### Using number of seconds from tmin for averaging function\n    diff_time_seconds = [i.total_seconds() for i in (t_insitu - tmin)]\n    bins_seconds = [i.total_seconds() for i in (t_insitu_hourly - tmin)]\n    #\n    # #### Averaging into bins\n    U_av, bin_edges, _ = binned_statistic(diff_time_seconds, [U_insitu*cosd(Orientation_insitu), U_insitu*sind(Orientation_insitu)],\n                                          bins=bins_seconds, statistic=np.nanmean)\n    #\n    Orientation_av = (np.arctan2(U_av[1, :], U_av[0, :])*180/np.pi) % 360  # orientation time series\n    U_av = np.linalg.norm(U_av, axis=0)  # velocity time series\n    bin_centered = bin_edges[1:] - (bin_edges[1] - bin_edges[0])/2\n    t_insitu_avg = tmin + np.array([timedelta(seconds=i) for i in bin_centered])\n    # Note: at this point, the in situ data are mapped on the ERA5 time steps, with a lot of NaNs where there was no in situ data.\n    #\n    ############################################################################\n    # Filtering unusued data (NaNs, 0 velocity)\n    ############################################################################\n    mask = (~ (np.isnan(U_av) | np.isnan(Orientation_av))) & (U_av > 0)\n    #\n    # #### Storing data into dictionnary\n    Data[station]['U_insitu'] = U_av[mask]\n    Data[station]['Orientation_insitu'] = Orientation_av[mask]\n    Data[station]['time'] = t_insitu_avg[mask]\n    Data[station]['z_insitu'] = Data_insitu['z_mes']\n    #\n    Data[station]['U_era'] = U_era[mask]\n    Data[station]['Orientation_era'] = Orientation_era[mask]\n    Data[station]['z_ERA5LAND'] = 10  # [m]\n    #\n    ############################################################################\n    # If available, do the same for the meteorological data from Era5\n    ############################################################################\n    if station in ['South_Namib_Station', 'Deep_Sea_Station']:\n        # BLH\n        path_BLH = [file for file in list_file_ERA5 if (station in file) & ('BLH' in file)][0]\n        Data_BLH = np.load(path_BLH, allow_pickle=True).item()\n        Data[station]['Boundary layer height'] = Data_BLH['blh'].squeeze()[mask]\n        # Pressure level data\n        path_level = [file for file in list_file_ERA5 if (station in file) & ('levels' in file)][0]\n        Data_level = np.load(path_level, allow_pickle=True).item()\n        Data[station]['Pressure levels'] = np.array(Data_level['levels'])\n        inds_mask = np.arange(t_era.size)[mask]\n        for key in Data_level.keys():\n            if key not in ['time', 'levels', 'latitude', 'longitude']:\n                Data[station][Names[key]] = Data_level[key].squeeze()[..., inds_mask]\n\npath_save = os.path.join(path_outputdata, 'Data_preprocessed.npy')\nnp.save(path_save, Data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}